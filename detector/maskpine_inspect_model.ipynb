{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of maskpine_inspect_model_160images_coco_30epochs_AUG_all3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1P1q258I1D4WhjkfB1333JugzxaXt71wK",
      "authorship_tag": "ABX9TyNb+f8ysjQhkSAWS6KwyOqc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jess-cah/measure-pineapple/blob/main/detector/maskpine_inspect_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pgi9P0oIvSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc8198a-bca5-4862-e143-306243f3e200"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_c7dxbGaQP50",
        "outputId": "44bb09ac-b2e5-4f38-cc98-4a05186b3534"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uCeoO9rhQVqX",
        "outputId": "dae05a1c-ae34-4335-dde1-97280d6e57cc"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Pines_Mask_RCNN/Mask_RCNN\")\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/Pines_Mask_RCNN/Mask_RCNN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mSPh_tgQXqI"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgE56BJcQatg"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip3 install Keras==2.0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLUR8ZzhImwP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45a59e83-dd4a-4041-e3c6-0916e67b6611"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/Pines_Mask_RCNN/Mask_RCNN/samples/pineappleResNet50_aug\")\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Pines_Mask_RCNN/Mask_RCNN/samples/pineappleResNet50_aug'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpEsft2xQ30O"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.patches as patches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXc3HUcVJOZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ca0bfe-66a5-4eaa-d24a-9d706a1ec9a0"
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "import pineapple\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5r1mK6HDfEa"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko4RTWUFDXTy"
      },
      "source": [
        "config = pineapple.PineappleConfig()\n",
        "PINEAPPLE_DIR = os.path.join(ROOT_DIR, \"datasets/pineapple160\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SoPC54gDqiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc19bd1-0e00-4ec1-b98f-c097f6891f8c"
      },
      "source": [
        "# Override the training configurations with a few\n",
        "# changes for inferencing.\n",
        "class InferenceConfig(config.__class__):\n",
        "    # Run detection on one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet50\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           pineapple\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjr392LFEBn5"
      },
      "source": [
        "#Notebook preferences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4A34X0ID-xJ"
      },
      "source": [
        "# Useful if you're training a model on the same \n",
        "# machine, in which case use CPU and leave the\n",
        "# GPU for training.\n",
        "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# TODO: code for 'training' test mode not ready yet\n",
        "TEST_MODE = \"inference\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSZ7dHVvEHt7"
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUqbUyLREMOh"
      },
      "source": [
        "#Load validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-kUGVsWEOD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88575ed4-4f97-4064-e69e-8071703706cc"
      },
      "source": [
        "# Load validation dataset\n",
        "dataset = pineapple.PineappleDataset()\n",
        "dataset.load_pineapple(PINEAPPLE_DIR, \"val\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images: 32\n",
            "Classes: ['BG', 'pineapple']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvvb5pOsE4CY"
      },
      "source": [
        "#Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXNW8hcuE7NT"
      },
      "source": [
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ALUHtdjLQgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff54c25-54d6-450d-eb9b-092ad3f04453"
      },
      "source": [
        "# Download file from the Releases page and set its path\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "#USED THIS ONE \n",
        "weights_path = \"/content/drive/MyDrive/Colab Notebooks/Pines_Mask_RCNN/Mask_RCNN/logs/pineapple20201116T1748/mask_rcnn_pineapple_0029.h5\"\n",
        "\n",
        "# Or, load the last model you trained\n",
        "#weights_path = model.find_last()\n",
        "\n",
        "# Load weights\n",
        "print(\"Loading weights \", weights_path)\n",
        "model.load_weights(weights_path, by_name=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights  /content/drive/MyDrive/Colab Notebooks/Pines_Mask_RCNN/Mask_RCNN/logs/pineapple20201116T1748/mask_rcnn_pineapple_0029.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:158: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:163: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:333: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:341: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Re-starting from epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrQmeffru6Ko"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RID5Z5KOuzXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc846c9-cc47-4c55-a88b-764e1ca4fa7a"
      },
      "source": [
        "# USING APPROACH FROM TRAIN_SHAPES.IPYNB - USING COMPUTE_AP FUNCTION\n",
        "# https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "inference_config = InferenceConfig()\n",
        "image_ids = dataset.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mAP:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDD2UeCc90Mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f37ab97-13da-4792-c332-a54667e2addf"
      },
      "source": [
        "# USING COMPUTE_AP_RANGE FROM UTILS\n",
        "# using code from https://www.kaggle.com/ipythonx/keras-global-wheat-detection-with-mask-rcnn\n",
        "\n",
        "# keep track of how long it takes\n",
        "%%time\n",
        "\n",
        "thresh_score = [0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8, 0.85, 0.9, 0.95]\n",
        "\n",
        "def evaluate_threshold_range(test_set, image_ids, model, \n",
        "                             iou_thresholds, inference_config):\n",
        "    '''Calculate mAP based on iou_threshold range\n",
        "    inputs:\n",
        "        test_set        : test samples\n",
        "        image_ids       : image ids of the test samples\n",
        "        model           : trained model\n",
        "        inference_config: test configuration\n",
        "        iou_threshold   : by default [0.5:0.95:0.05]\n",
        "    return:\n",
        "        AP : mAP[@0.5:0.95] scores lists of the test samples\n",
        "    '''\n",
        "    # placeholder for all the ap of all classes for IoU socres 0.5 to 0.95 with step size 0.05\n",
        "    AP = []\n",
        "    np.seterr(divide='ignore', invalid='ignore') \n",
        "    \n",
        "    for image_id in image_ids:\n",
        "        # Load image and ground truth data\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(test_set, inference_config,\n",
        "                                   image_id, use_mini_mask=False)\n",
        "\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        r = results[0]\n",
        "        AP_range = utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask, \n",
        "                                          r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],\n",
        "                                          iou_thresholds=iou_thresholds, verbose=0)\n",
        "        \n",
        "        if math.isnan(AP_range):\n",
        "            continue\n",
        "            \n",
        "        # append the scores of each samples\n",
        "        AP.append(AP_range)   \n",
        "        \n",
        "    return AP\n",
        "\n",
        "AP = evaluate_threshold_range(dataset, dataset.image_ids,\n",
        "                              model, thresh_score, inference_config)\n",
        "\n",
        "print(\"AP[0.5:0.95]: \", np.mean(AP))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AP[0.5:0.95]:  0.9026214366853127\n",
            "CPU times: user 12min 5s, sys: 10.8 s, total: 12min 16s\n",
            "Wall time: 6min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}